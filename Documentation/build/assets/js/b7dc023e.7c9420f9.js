"use strict";(self.webpackChunkeliza_docs=self.webpackChunkeliza_docs||[]).push([[79207],{59701:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"Discord/development/coders/chat_2024-11-24","title":"\ud83d\udcbb-coders 2024-11-24","description":"Summary","source":"@site/community/Discord/development/coders/chat_2024-11-24.md","sourceDirName":"Discord/development/coders","slug":"/Discord/development/coders/chat_2024-11-24","permalink":"/eliza/community/Discord/development/coders/chat_2024-11-24","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"defaultSidebar","previous":{"title":"\ud83d\udcbb-coders 2024-11-23","permalink":"/eliza/community/Discord/development/coders/chat_2024-11-23"},"next":{"title":"\ud83d\udcbb-coders 2024-11-25","permalink":"/eliza/community/Discord/development/coders/chat_2024-11-25"}}');var s=i(62540),o=i(43023);const r={},a="\ud83d\udcbb-coders 2024-11-24",l={},d=[{value:"Summary",id:"summary",level:2},{value:"FAQ",id:"faq",level:2},{value:"Who Helped Who",id:"who-helped-who",level:2},{value:"Action Items",id:"action-items",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"-coders-2024-11-24",children:"\ud83d\udcbb-coders 2024-11-24"})}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"During the technical discussion, Ophiuchus shared plans to push code for a Twitter scraper by week's end, aiming to capture responses from replies while excluding simple replies, image posts, and threads that the scraper could handle. The team expressed interest in seeing how finetuning on this data would impact results compared to using RAG models. Ferric highlighted the need for GPU time when fine-tuning due to Gemini's extensive token context. Loaf suggested starting from a TypeScript file and mentioned plans to move away from JSON, although implementation is pending. Jmill provided examples of initializing agents with character data in TypeScript files, noting that characters are loaded based on command line arguments or fallback defaults. Tony AI Champ clarified the distinction between fine-tuning for personality adjustments and RAG models for knowledge acquisition, emphasizing that fine-tuning only modifies a small number of weights while keeping most parameters unchanged."}),"\n",(0,s.jsx)(n.h2,{id:"faq",children:"FAQ"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"What is the difference between fine-tuning and RAG in terms of knowledge acquisition?"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Tony AI Champ: Fine-tuning can be thought of as adjusting a model's personality, while RAG (Retrieval-Augmented Generation) focuses on acquiring new knowledge. In the case of Eliza, fine-tuning changes only a small number of weights and keeps everything else constant, making it less effective for gaining extensive knowledge compared to RAG."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"How can one resolve an error related to missing modules or type declarations in Node.js projects?"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Faith: To solve the issue with '@ai16z/eliza' module not found, ensure that you have installed all necessary dependencies using ",(0,s.jsx)(n.code,{children:"pnpm i"})," and check if your project is correctly configured for TypeScript by verifying the presence of a ",(0,s.jsx)(n.code,{children:".tsconfig"})," file. Additionally, make sure to install type declarations (if available) or define them manually in your project."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"How can one start from a TypeScript (.ts) file when working with Eliza?"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["loaf: To work with Eliza using TypeScript files, you need to load the plugin and parse arguments accordingly. You may also consider moving away from JSON format but note that this feature has not been implemented yet. The ",(0,s.jsx)(n.code,{children:"loadCharacters"})," function expects a string input rather than an object, so ensure your code is compatible with these requirements."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"who-helped-who",children:"Who Helped Who"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Ophiuchus helped Faith with a module error by discussing potential solutions to the '@ai16z/eliza' module issue. The success of this interaction is not explicitly stated, but it provided guidance for troubleshooting."}),"\n",(0,s.jsx)(n.li,{children:"loaf helped jmill with understanding how to start from a TypeScript file and load characters in their project by explaining the process and mentioning plans to move away from JSON. This was successful as it clarified the steps needed for jmill's task."}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"action-items",children:"Action Items"}),"\n",(0,s.jsx)(n.p,{children:"Technical Tasks:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Fixing the module import error '@ai16z/eliza' (mentioned by Faith)"}),"\n",(0,s.jsx)(n.li,{children:"Implementing finetuning on a codebase and knowledge addition (discussed by Ophiuchus)"}),"\n",(0,s.jsx)(n.li,{children:"Moving away from JSON to another format in future updates, but not yet implemented (loaf mentioned this as a plan)"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Documentation Needs:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"No specific documentation needs were explicitly requested."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Feature Requests:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Implementing finetuning for knowledge addition instead of RAG models (Ophiuchus suggested this idea)"}),"\n",(0,s.jsx)(n.li,{children:"Removing replies or short ones from Twitter scraper training data to improve results (Ophiuchus mentioned this as a consideration)"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Community Tasks:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Pushing code by the end of the week on the Twitter scraper project (led by Ophiuchus)"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},43023:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var t=i(63696);const s={},o=t.createContext(s);function r(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);