"use strict";(self.webpackChunkeliza_docs=self.webpackChunkeliza_docs||[]).push([[99047],{33468:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>m,frontMatter:()=>l,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"advanced/fine-tuning","title":"\ud83c\udfaf Fine-tuning Guide","description":"Overview","source":"@site/docs/advanced/fine-tuning.md","sourceDirName":"advanced","slug":"/advanced/fine-tuning","permalink":"/eliza/docs/advanced/fine-tuning","draft":false,"unlisted":false,"editUrl":"https://github.com/ai16z/eliza/tree/main/docs/docs/advanced/fine-tuning.md","tags":[],"version":"current","sidebarPosition":13,"frontMatter":{"sidebar_position":13},"sidebar":"tutorialSidebar","previous":{"title":"Local Development","permalink":"/eliza/docs/guides/local-development"},"next":{"title":"Infrastructure","permalink":"/eliza/docs/advanced/infrastructure"}}');var t=i(62540),r=i(43023);const l={sidebar_position:13},a="\ud83c\udfaf Fine-tuning Guide",o={},d=[{value:"Overview",id:"overview",level:2},{value:"Model Providers",id:"model-providers",level:2},{value:"Provider Configuration",id:"provider-configuration",level:3},{value:"Model Classes",id:"model-classes",level:2},{value:"Embedding System",id:"embedding-system",level:2},{value:"Configuration",id:"configuration",level:3},{value:"Implementation",id:"implementation",level:3},{value:"Fine-tuning Options",id:"fine-tuning-options",level:2},{value:"Temperature Control",id:"temperature-control",level:3},{value:"Context Window",id:"context-window",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Caching Strategy",id:"caching-strategy",level:3},{value:"Model Selection",id:"model-selection",level:3},{value:"Provider-Specific Optimizations",id:"provider-specific-optimizations",level:2},{value:"OpenAI",id:"openai",level:3},{value:"Anthropic",id:"anthropic",level:3},{value:"Local LLM",id:"local-llm",level:3},{value:"Heurist Provider",id:"heurist-provider",level:3},{value:"Testing and Validation",id:"testing-and-validation",level:2},{value:"Embedding Tests",id:"embedding-tests",level:3},{value:"Model Performance Testing",id:"model-performance-testing",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Model Selection Guidelines",id:"model-selection-guidelines",level:3},{value:"Performance Optimization",id:"performance-optimization-1",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Common Issues",id:"common-issues",level:3}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"-fine-tuning-guide",children:"\ud83c\udfaf Fine-tuning Guide"})}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:"Eliza supports multiple AI model providers and offers extensive configuration options for fine-tuning model behavior, embedding generation, and performance optimization."}),"\n",(0,t.jsx)(n.h2,{id:"model-providers",children:"Model Providers"}),"\n",(0,t.jsx)(n.p,{children:"Eliza supports multiple model providers through a flexible configuration system:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"enum ModelProviderName {\n  OPENAI,\n  ANTHROPIC,\n  CLAUDE_VERTEX,\n  GROK,\n  GROQ,\n  LLAMACLOUD,\n  LLAMALOCAL,\n  GOOGLE,\n  REDPILL,\n  OPENROUTER,\n  HEURIST,\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"provider-configuration",children:"Provider Configuration"}),"\n",(0,t.jsx)(n.p,{children:"Each provider has specific settings:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'const models = {\n  [ModelProviderName.ANTHROPIC]: {\n    settings: {\n      stop: [],\n      maxInputTokens: 200000,\n      maxOutputTokens: 8192,\n      frequency_penalty: 0.0,\n      presence_penalty: 0.0,\n      temperature: 0.3,\n    },\n    endpoint: "https://api.anthropic.com/v1",\n    model: {\n      [ModelClass.SMALL]: "claude-3-5-haiku",\n      [ModelClass.MEDIUM]: "claude-3-5-sonnet-20241022",\n      [ModelClass.LARGE]: "claude-3-5-opus-20240229",\n    },\n  },\n  // ... other providers\n};\n'})}),"\n",(0,t.jsx)(n.h2,{id:"model-classes",children:"Model Classes"}),"\n",(0,t.jsx)(n.p,{children:"Models are categorized into different classes based on their capabilities:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"enum ModelClass {\n    SMALL,    // Fast, efficient for simple tasks\n    MEDIUM,   // Balanced performance and capability\n    LARGE,    // Most capable but slower/more expensive\n    EMBEDDING // Specialized for vector embeddings\n    IMAGE     // Image generation capabilities\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"embedding-system",children:"Embedding System"}),"\n",(0,t.jsx)(n.h3,{id:"configuration",children:"Configuration"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'const embeddingConfig = {\n  dimensions: 1536,\n  modelName: "text-embedding-3-small",\n  cacheEnabled: true,\n};\n'})}),"\n",(0,t.jsx)(n.h3,{id:"implementation",children:"Implementation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'async function embed(runtime: IAgentRuntime, input: string): Promise<number[]> {\n  // Check cache first\n  const cachedEmbedding = await retrieveCachedEmbedding(runtime, input);\n  if (cachedEmbedding) return cachedEmbedding;\n\n  // Generate new embedding\n  const response = await runtime.fetch(\n    `${runtime.modelProvider.endpoint}/embeddings`,\n    {\n      method: "POST",\n      headers: {\n        Authorization: `Bearer ${runtime.token}`,\n        "Content-Type": "application/json",\n      },\n      body: JSON.stringify({\n        input,\n        model: runtime.modelProvider.model.EMBEDDING,\n        dimensions: 1536,\n      }),\n    },\n  );\n\n  const data = await response.json();\n  return data?.data?.[0].embedding;\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"fine-tuning-options",children:"Fine-tuning Options"}),"\n",(0,t.jsx)(n.h3,{id:"temperature-control",children:"Temperature Control"}),"\n",(0,t.jsx)(n.p,{children:"Configure model creativity vs. determinism:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"const temperatureSettings = {\n  creative: {\n    temperature: 0.8,\n    frequency_penalty: 0.7,\n    presence_penalty: 0.7,\n  },\n  balanced: {\n    temperature: 0.5,\n    frequency_penalty: 0.3,\n    presence_penalty: 0.3,\n  },\n  precise: {\n    temperature: 0.2,\n    frequency_penalty: 0.0,\n    presence_penalty: 0.0,\n  },\n};\n"})}),"\n",(0,t.jsx)(n.h3,{id:"context-window",children:"Context Window"}),"\n",(0,t.jsx)(n.p,{children:"Manage token limits:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"const contextSettings = {\n  OPENAI: {\n    maxInputTokens: 128000,\n    maxOutputTokens: 8192,\n  },\n  ANTHROPIC: {\n    maxInputTokens: 200000,\n    maxOutputTokens: 8192,\n  },\n  LLAMALOCAL: {\n    maxInputTokens: 32768,\n    maxOutputTokens: 8192,\n  },\n};\n"})}),"\n",(0,t.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,t.jsx)(n.h3,{id:"caching-strategy",children:"Caching Strategy"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'class EmbeddingCache {\n  private cache: NodeCache;\n  private cacheDir: string;\n\n  constructor() {\n    this.cache = new NodeCache({ stdTTL: 300 }); // 5 minute TTL\n    this.cacheDir = path.join(__dirname, "cache");\n  }\n\n  async get(key: string): Promise<number[] | null> {\n    // Check memory cache first\n    const cached = this.cache.get<number[]>(key);\n    if (cached) return cached;\n\n    // Check disk cache\n    return this.readFromDisk(key);\n  }\n\n  async set(key: string, embedding: number[]): Promise<void> {\n    this.cache.set(key, embedding);\n    await this.writeToDisk(key, embedding);\n  }\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"model-selection",children:"Model Selection"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'async function selectOptimalModel(\n  task: string,\n  requirements: ModelRequirements,\n): Promise<ModelClass> {\n  if (requirements.speed === "fast") {\n    return ModelClass.SMALL;\n  } else if (requirements.complexity === "high") {\n    return ModelClass.LARGE;\n  }\n  return ModelClass.MEDIUM;\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"provider-specific-optimizations",children:"Provider-Specific Optimizations"}),"\n",(0,t.jsx)(n.h3,{id:"openai",children:"OpenAI"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'const openAISettings = {\n  endpoint: "https://api.openai.com/v1",\n  settings: {\n    stop: [],\n    maxInputTokens: 128000,\n    maxOutputTokens: 8192,\n    frequency_penalty: 0.0,\n    presence_penalty: 0.0,\n    temperature: 0.6,\n  },\n  model: {\n    [ModelClass.SMALL]: "gpt-4o-mini",\n    [ModelClass.MEDIUM]: "gpt-4o",\n    [ModelClass.LARGE]: "gpt-4o",\n    [ModelClass.EMBEDDING]: "text-embedding-3-small",\n    [ModelClass.IMAGE]: "dall-e-3",\n  },\n};\n'})}),"\n",(0,t.jsx)(n.h3,{id:"anthropic",children:"Anthropic"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'const anthropicSettings = {\n  endpoint: "https://api.anthropic.com/v1",\n  settings: {\n    stop: [],\n    maxInputTokens: 200000,\n    maxOutputTokens: 8192,\n    temperature: 0.3,\n  },\n  model: {\n    [ModelClass.SMALL]: "claude-3-5-haiku",\n    [ModelClass.MEDIUM]: "claude-3-5-sonnet-20241022",\n    [ModelClass.LARGE]: "claude-3-5-opus-20240229",\n  },\n};\n'})}),"\n",(0,t.jsx)(n.h3,{id:"local-llm",children:"Local LLM"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'const llamaLocalSettings = {\n  settings: {\n    stop: ["<|eot_id|>", "<|eom_id|>"],\n    maxInputTokens: 32768,\n    maxOutputTokens: 8192,\n    repetition_penalty: 0.0,\n    temperature: 0.3,\n  },\n  model: {\n    [ModelClass.SMALL]: "NousResearch/Hermes-3-Llama-3.1-8B-GGUF",\n    [ModelClass.MEDIUM]: "NousResearch/Hermes-3-Llama-3.1-8B-GGUF",\n    [ModelClass.LARGE]: "NousResearch/Hermes-3-Llama-3.1-8B-GGUF",\n    [ModelClass.EMBEDDING]: "togethercomputer/m2-bert-80M-32k-retrieval",\n  },\n};\n'})}),"\n",(0,t.jsx)(n.h3,{id:"heurist-provider",children:"Heurist Provider"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'const heuristSettings = {\n  settings: {\n    stop: [],\n    maxInputTokens: 32768,\n    maxOutputTokens: 8192,\n    repetition_penalty: 0.0,\n    temperature: 0.7,\n  },\n  imageSettings: {\n    steps: 20,\n  },\n  endpoint: "https://llm-gateway.heurist.xyz",\n  model: {\n    [ModelClass.SMALL]: "hermes-3-llama3.1-8b",\n    [ModelClass.MEDIUM]: "mistralai/mixtral-8x7b-instruct",\n    [ModelClass.LARGE]: "nvidia/llama-3.1-nemotron-70b-instruct",\n    [ModelClass.EMBEDDING]: "", // Add later\n    [ModelClass.IMAGE]: "FLUX.1-dev",\n  },\n};\n'})}),"\n",(0,t.jsx)(n.h2,{id:"testing-and-validation",children:"Testing and Validation"}),"\n",(0,t.jsx)(n.h3,{id:"embedding-tests",children:"Embedding Tests"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'async function validateEmbedding(\n  embedding: number[],\n  expectedDimensions: number = 1536,\n): Promise<boolean> {\n  if (!Array.isArray(embedding)) return false;\n  if (embedding.length !== expectedDimensions) return false;\n  if (embedding.some((n) => typeof n !== "number")) return false;\n  return true;\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"model-performance-testing",children:"Model Performance Testing"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"async function benchmarkModel(\n  runtime: IAgentRuntime,\n  modelClass: ModelClass,\n  testCases: TestCase[],\n): Promise<BenchmarkResults> {\n  const results = {\n    latency: [],\n    tokenUsage: [],\n    accuracy: [],\n  };\n\n  for (const test of testCases) {\n    const start = Date.now();\n    const response = await runtime.generateText({\n      context: test.input,\n      modelClass,\n    });\n    results.latency.push(Date.now() - start);\n    // ... additional metrics\n  }\n\n  return results;\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,t.jsx)(n.h3,{id:"model-selection-guidelines",children:"Model Selection Guidelines"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Task Complexity"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use SMALL for simple, quick responses"}),"\n",(0,t.jsx)(n.li,{children:"Use MEDIUM for balanced performance"}),"\n",(0,t.jsx)(n.li,{children:"Use LARGE for complex reasoning"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Context Management"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Keep prompts concise and focused"}),"\n",(0,t.jsx)(n.li,{children:"Use context windows efficiently"}),"\n",(0,t.jsx)(n.li,{children:"Implement proper context truncation"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Temperature Adjustment"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Lower for factual responses"}),"\n",(0,t.jsx)(n.li,{children:"Higher for creative tasks"}),"\n",(0,t.jsx)(n.li,{children:"Balance based on use case"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"performance-optimization-1",children:"Performance Optimization"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Caching Strategy"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Cache embeddings for frequently accessed content"}),"\n",(0,t.jsx)(n.li,{children:"Implement tiered caching (memory/disk)"}),"\n",(0,t.jsx)(n.li,{children:"Regular cache cleanup"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Resource Management"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Monitor token usage"}),"\n",(0,t.jsx)(n.li,{children:"Implement rate limiting"}),"\n",(0,t.jsx)(n.li,{children:"Optimize batch processing"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,t.jsx)(n.h3,{id:"common-issues",children:"Common Issues"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Token Limits"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'function handleTokenLimit(error: Error) {\n  if (error.message.includes("token limit")) {\n    return truncateAndRetry();\n  }\n}\n'})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Embedding Errors"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'function handleEmbeddingError(error: Error) {\n  if (error.message.includes("dimension mismatch")) {\n    return regenerateEmbedding();\n  }\n}\n'})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Model Availability"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'async function handleModelFailover(error: Error) {\n  if (error.message.includes("model not available")) {\n    return switchToFallbackModel();\n  }\n}\n'})}),"\n"]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},43023:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>a});var s=i(63696);const t={},r=s.createContext(t);function l(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);