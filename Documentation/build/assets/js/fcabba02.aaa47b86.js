"use strict";(self.webpackChunkeliza_docs=self.webpackChunkeliza_docs||[]).push([[84414],{36057:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"Discord/development/coders/chat_2024-11-01","title":"\ud83d\udcbb-coders 2024-11-01","description":"Summary","source":"@site/community/Discord/development/coders/chat_2024-11-01.md","sourceDirName":"Discord/development/coders","slug":"/Discord/development/coders/chat_2024-11-01","permalink":"/eliza/community/Discord/development/coders/chat_2024-11-01","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"defaultSidebar","previous":{"title":"\ud83d\udcbb-coders 2024-10-31","permalink":"/eliza/community/Discord/development/coders/chat_2024-10-31"},"next":{"title":"\ud83d\udcbb-coders 2024-11-02","permalink":"/eliza/community/Discord/development/coders/chat_2024-11-02"}}');var o=i(62540),s=i(43023);const r={},a="\ud83d\udcbb-coders 2024-11-01",l={},c=[{value:"Summary",id:"summary",level:2},{value:"FAQ",id:"faq",level:2},{value:"Who Helped Who",id:"who-helped-who",level:2},{value:"Action Items",id:"action-items",level:2}];function h(e){const n={h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"-coders-2024-11-01",children:"\ud83d\udcbb-coders 2024-11-01"})}),"\n",(0,o.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(n.p,{children:"In the technical discussion, LevelsDennis sought advice on transitioning to llama3.2 locally, while smokyboo shared their success in getting ollama working without using a fork, planning to integrate it with the openai lib for better functionality. HiroP mentioned integrating a custom behavior pack (BP) into Unreal Engine (UE), which processes HTTP requests and facilitates text entry interactions, potentially expanding to voice commands. Jin provided an overview of Eliza's notes from hackmd.io, indicating intentions to edit the vod for further clarity. Ferric expressed excitement about these developments on stakeware.xyz, while SotoAlt proposed creating a guide with screenshots for newcomers and inquired about recording the stream. Tenji discovered how to integrate cloud llm using together.xyz, prompting ferric to mention MetaLlama 405B's training data sets on Together.xyz for Spartan."}),"\n",(0,o.jsx)(n.h2,{id:"faq",children:"FAQ"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"How do you transition your agent to llama3.2 running locally?"}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"hiroP: He is in the process of making this transition and asks for any advice or tips from others who have done so before. The conversation does not provide a clear step-by-step explanation, but it shows that he's seeking community support."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Has anyone tried llama3.2 yet?"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"LevelsDennis: He has not tried llama3.2 yet at the time of this conversation."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"How many more agents do you have to transition after hiroP?"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"hiroP: He mentions that he only has 20 more agents left to transition, indicating his progress in moving from one version to another."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"What is a potential fun use for llama3.2 mentioned by yikesawjeez?"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"yikesawjeez: They suggest using the hivemind feature of llama3.2 and shared a SoundCloud link related to it, which could be an interesting application or experiment with this technology."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"What error is smokyboo experiencing while working on ollama?"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"smokyboo: The conversation does not specify the exact error experienced by smokyboo; however, they mention that they managed to get ollama working locally and are planning to make it work with the openai lib."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"How did hiroP wire up his custom BP for UE?"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"hiroP: He explains that he created a custom Behavior Plugin (BP) which handles HTTP requests, allowing in-world objects to spawn UI elements and communicate via text or voice with the agent running locally. This setup facilitates interaction between users and agents within Unreal Engine (UE)."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"What data sets was MetaLlama 405B trained on?"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Tenji: The question is asked, but no clear answer is provided in this conversation. However, ferric mentions using MetaLlama 405B with Together.xyz for Spartan, which might imply that the data sets used are related to their specific use case or project."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"who-helped-who",children:"Who Helped Who"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"smokyboo helped hiroP with setting up a local model by managing to get ollama working locally without using their fork and planning to make it work with openai lib."}),"\n",(0,o.jsx)(n.li,{children:"jin helped SotoAlt | WAWE with providing resources for Eliza's overview, which included sharing notes from an overview of eliza on HackMD."}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"action-items",children:"Action Items"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Technical Tasks"}),"\n",(0,o.jsx)(n.li,{children:"Trying out llama (mentioned by LevelsDennis)"}),"\n",(0,o.jsx)(n.li,{children:"Getting ollama working locally without using the fork and interacting raw with fetch (mentioned by smokyboo)"}),"\n",(0,o.jsx)(n.li,{children:"Making it work with openai lib for ollama (mentioned by smokyboo)"}),"\n",(0,o.jsx)(n.li,{children:"Wiring up to UE with a custom BP handling HTTP requests (mentioned by hiroP)"}),"\n",(0,o.jsxs)(n.li,{children:["Documentation Needs","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Sharing the recording of the stream and possibly creating a short guide with screenshots for newcomers (requested by SotoAlt | WAWE)"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["Feature Requests","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Intercepting microphone input for voice interaction in UE setup (mentioned by hiroP)"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["Community Tasks","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Sharing the VOD of the stream and possibly creating a short guide with screenshots for newcomers (led by Jin)"}),"\n"]}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}},43023:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var t=i(63696);const o={},s=t.createContext(o);function r(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);